---
title: "R Notebook"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code.

Import libraries:

```{r warning=FALSE}
library(here) # avoid absolute paths
library(reticulate) # allows us to use python
reticulate::use_virtualenv(here::here("venv"))

library(sf) # r geospatial library
library(httr) # http request library

library(dplyr)
library(ggplot2)

world <- map_data("world")
worldMap <- ggplot() + geom_map(data = world,
                                map = world, aes(long, lat, map_id = region)) 

```

## MapServer Open Data records:
Example Open data source: https://open.canada.ca/data/en/dataset/da99526e-284f-4e06-8d04-193785cd1a96
Map server url: https://maps-cartes.ec.gc.ca/arcgis/rest/services/Active_Inactive_Disposal_at_Sea_Sites/MapServer

```{r}
# set up 
mapServerUrl <- "https://maps-cartes.ec.gc.ca/arcgis/rest/services/Active_Inactive_Disposal_at_Sea_Sites/MapServer"
layer = "0"
```

Build an http request:
```{r}
url <- httr::parse_url(mapServerUrl)
url$path <- paste(url$path, layer, "query", sep = "/")

url$query <- list(where = "OBJECTID>0", # filter results, default is to select all
                  outFields = "*", # select all fields
                  returnGeometry = "true",
                  f = "geojson") # return the results as a geojson

requestUrl <- httr::build_url(url)
requestUrl
```
Read in the geojson into an sf object
```{r}
# you can enter the request object into a browser to access the raw geojson returned from the query
data_sf <- sf::st_read(requestUrl) %>% sf::st_make_valid()
head(data_sf)

```

```{r}
atlantic_sf <- dplyr::filter(data_sf, Region == "Atlantic")

#bbox <- sf::st_bbox(atlantic_sf[1, ])
bbox <- sf::st_bbox(atlantic_sf)
worldMap +
  geom_sf(data=dplyr::select(atlantic_sf, "Material"), 
          col = "darkred", 
          lwd=2) +
  coord_sf(xlim = c(bbox$xmin, bbox$xmax),
           ylim = c(bbox$ymin, bbox$ymax), 
           expand = FALSE)
```
Save our data to a shapefile:

```{r}
sf::st_write(atlantic_sf, here::here("temp/atlantic.shp"), delete_dsn=TRUE)
```

Function based approach:
```{r}
get_esri_rest <- function(mapServerUrl, layer="1", where="OBJECTID>0") {
  url <- httr::parse_url(mapServerUrl)
  url$path <- paste(url$path, layer, "query", sep = "/")
  url$query <- list(where = where, 
                    outFields = "*",
                    returnGeometry = "true",
                    f = "geojson") 
  request <- httr::build_url(url)
  out_sf <- sf::st_read(request)
  return(out_sf)
}


url <- "https://maps-cartes.ec.gc.ca/arcgis/rest/services/Active_Inactive_Disposal_at_Sea_Sites/MapServer"
data_sf <- get_esri_rest(url, layer="0")
data_sf <- get_esri_rest(url, layer="0", where="SiteCode = 'CA-AT-D004'")
```




```{python}
import requests
import json
from shapely.geometry import shape, GeometryCollection
import geopandas as gpd


base_url = "https://maps-cartes.ec.gc.ca/arcgis/rest/services/Active_Inactive_Disposal_at_Sea_Sites/MapServer"
layer = "0"

url = base_url + "/" + layer + "/query"
query_params = {"where":"OBJECTID>0", "outFields" : "*", "returnGeometry" : "true", "f" : "geojson"}
response_object = requests.get(url, params=query_params)
```
Load the response into a shapely object:

```{python}
if response_object.ok:
  features = response_object.json()["features"]
  data_df = gpd.GeoDataFrame.from_features(features)
  shapely_coll = GeometryCollection([shape(feature["geometry"]).buffer(0) for feature in features])

```